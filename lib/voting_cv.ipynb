{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models have been tuned and tested in this notebook\n",
    "# Was not run for the final deliverable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature90</th>\n",
       "      <th>feature91</th>\n",
       "      <th>feature92</th>\n",
       "      <th>feature93</th>\n",
       "      <th>feature94</th>\n",
       "      <th>feature95</th>\n",
       "      <th>feature96</th>\n",
       "      <th>feature97</th>\n",
       "      <th>feature98</th>\n",
       "      <th>emotion_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>116.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0      64.0     127.0      65.0      63.0       1.0      62.0       5.0   \n",
       "1      64.0     127.0      64.0      63.0       0.0      63.0       7.0   \n",
       "2      69.0     137.0      69.0      68.0       0.0      68.0       4.0   \n",
       "3      61.0     123.0      62.0      62.0       1.0      61.0       3.0   \n",
       "4      66.0     131.0      66.0      65.0       0.0      65.0       1.0   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature90  feature91  feature92  \\\n",
       "0       8.0       4.0       13.0  ...       88.0      175.0      315.0   \n",
       "1       4.0       7.0       11.0  ...      116.0      198.0      327.0   \n",
       "2       6.0       3.0        2.0  ...       97.0      175.0      300.0   \n",
       "3       3.0       2.0        6.0  ...       96.0      193.0      323.0   \n",
       "4       3.0       1.0        2.0  ...       98.0      179.0      297.0   \n",
       "\n",
       "   feature93  feature94  feature95  feature96  feature97  feature98  \\\n",
       "0       88.0      175.0      315.0       87.0      227.0      140.0   \n",
       "1      111.0      193.0      322.0       82.0      211.0      129.0   \n",
       "2       98.0      176.0      301.0       78.0      203.0      125.0   \n",
       "3       97.0      194.0      324.0       97.0      227.0      130.0   \n",
       "4      100.0      181.0      299.0       81.0      199.0      118.0   \n",
       "\n",
       "   emotion_idx  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pyreadr.read_r('myfeature2.RData')['datcomb']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_idx, test_idx = train_test_split(range(2500), test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "test_df = df.iloc[test_idx].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature90</th>\n",
       "      <th>feature91</th>\n",
       "      <th>feature92</th>\n",
       "      <th>feature93</th>\n",
       "      <th>feature94</th>\n",
       "      <th>feature95</th>\n",
       "      <th>feature96</th>\n",
       "      <th>feature97</th>\n",
       "      <th>feature98</th>\n",
       "      <th>emotion_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0      63.0     128.0      62.0      65.0       1.0      66.0      18.0   \n",
       "1      61.0     124.0      62.0      63.0       1.0      62.0      15.0   \n",
       "2      63.0     127.0      66.0      64.0       3.0      61.0      10.0   \n",
       "3      76.0     151.0      76.0      75.0       0.0      75.0       8.0   \n",
       "4      76.0     145.0      78.0      69.0       2.0      67.0      16.0   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature90  feature91  feature92  \\\n",
       "0      16.0      20.0        2.0  ...       34.0      137.0      273.0   \n",
       "1       2.0      12.0       13.0  ...      105.0      174.0      308.0   \n",
       "2       5.0      12.0        5.0  ...       80.0      150.0      279.0   \n",
       "3       9.0       2.0        1.0  ...       40.0      142.0      260.0   \n",
       "4       3.0      30.0       13.0  ...       63.0      153.0      273.0   \n",
       "\n",
       "   feature93  feature94  feature95  feature96  feature97  feature98  \\\n",
       "0       59.0      162.0      298.0      103.0      239.0      136.0   \n",
       "1      103.0      172.0      306.0       69.0      203.0      134.0   \n",
       "2       85.0      155.0      284.0       70.0      199.0      129.0   \n",
       "3       61.0      163.0      281.0      102.0      220.0      118.0   \n",
       "4       59.0      149.0      269.0       90.0      210.0      120.0   \n",
       "\n",
       "   emotion_idx  \n",
       "0            1  \n",
       "1           22  \n",
       "2           21  \n",
       "3            7  \n",
       "4            8  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.iloc[:,:-1]\n",
    "y_train = train_df.iloc[:,-1]\n",
    "X_test = test_df.iloc[:,:-1]\n",
    "y_test = test_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed:   51.4s remaining:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  4.3min finished\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators':[100, 200, 500, 1000]}\n",
    "lgb = LGBMClassifier(random_state=0, objective='multiclass', boosting_type = 'dart', max_bin = 510,\n",
    "                    colsample_pytree = 0.7, subsample=0.7)\n",
    "clf = GridSearchCV(lgb, params, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "n_estimators = clf.best_params_['n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators #1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed: 14.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=LGBMClassifier(boosting_type='dart', class_weight=None,\n",
       "                                      colsample_bytree=1.0,\n",
       "                                      colsample_pytree=0.7,\n",
       "                                      importance_type='split',\n",
       "                                      learning_rate=0.1, max_bin=510,\n",
       "                                      max_depth=-1, min_child_samples=20,\n",
       "                                      min_child_weight=0.001,\n",
       "                                      min_split_gain=0.0, n_estimators=1000,\n",
       "                                      n_jobs=-1, num_leaves=31,\n",
       "                                      objective='multiclass', random_state=0,\n",
       "                                      reg_alpha=0.0, reg_lambda=0.0,\n",
       "                                      silent=True, subsample=0.7,\n",
       "                                      subsample_for_bin=200000,\n",
       "                                      subsample_freq=0),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.1, 0.05, 0.01],\n",
       "                         'max_depth': [3, 5, 7]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'learning_rate':[0.1, 0.05, 0.01],\n",
    "          'max_depth':[3, 5, 7]}\n",
    "\n",
    "lgb = LGBMClassifier(n_estimators=n_estimators, random_state=0, objective='multiclass', boosting_type = 'dart', max_bin = 510,\n",
    "                    colsample_pytree = 0.7, subsample=0.7)\n",
    "\n",
    "clf = GridSearchCV(lgb, params, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 7}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = clf.best_params_\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([131.28398999, 241.23224807, 321.20204258, 138.57607166,\n",
       "        266.24795604, 357.16434439, 148.56951467, 241.74444222,\n",
       "        249.62682215]),\n",
       " 'std_fit_time': array([3.26830528, 3.06260503, 5.39775397, 3.51619127, 9.77493329,\n",
       "        5.00437522, 5.95579816, 4.67528623, 7.86431842]),\n",
       " 'mean_score_time': array([2.73934563, 5.1798238 , 4.80615481, 2.96116765, 4.41623092,\n",
       "        5.1718444 , 3.46241268, 3.49948208, 3.05352934]),\n",
       " 'std_score_time': array([0.06954831, 0.79689532, 0.23724099, 0.2517141 , 0.12113394,\n",
       "        0.06683563, 0.85233726, 0.1705045 , 0.13203459]),\n",
       " 'param_learning_rate': masked_array(data=[0.1, 0.1, 0.1, 0.05, 0.05, 0.05, 0.01, 0.01, 0.01],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[3, 5, 7, 3, 5, 7, 3, 5, 7],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_rate': 0.1, 'max_depth': 3},\n",
       "  {'learning_rate': 0.1, 'max_depth': 5},\n",
       "  {'learning_rate': 0.1, 'max_depth': 7},\n",
       "  {'learning_rate': 0.05, 'max_depth': 3},\n",
       "  {'learning_rate': 0.05, 'max_depth': 5},\n",
       "  {'learning_rate': 0.05, 'max_depth': 7},\n",
       "  {'learning_rate': 0.01, 'max_depth': 3},\n",
       "  {'learning_rate': 0.01, 'max_depth': 5},\n",
       "  {'learning_rate': 0.01, 'max_depth': 7}],\n",
       " 'split0_test_score': array([0.3768546 , 0.384273  , 0.40801187, 0.37833828, 0.38724036,\n",
       "        0.39614243, 0.36795252, 0.38130564, 0.37091988]),\n",
       " 'split1_test_score': array([0.38646617, 0.36691729, 0.37593985, 0.38646617, 0.36691729,\n",
       "        0.38345865, 0.36992481, 0.36691729, 0.3593985 ]),\n",
       " 'split2_test_score': array([0.37821483, 0.37972769, 0.38577912, 0.37670197, 0.3827534 ,\n",
       "        0.37065053, 0.35400908, 0.38729198, 0.3903177 ]),\n",
       " 'mean_test_score': array([0.3805, 0.377 , 0.39  , 0.3805, 0.379 , 0.3835, 0.364 , 0.3785,\n",
       "        0.3735]),\n",
       " 'std_test_score': array([0.00424731, 0.00735441, 0.01345182, 0.00426353, 0.00872249,\n",
       "        0.01041308, 0.00706588, 0.00853276, 0.01272159]),\n",
       " 'rank_test_score': array([3, 7, 1, 3, 5, 2, 9, 6, 8])}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = clf.cv_results_\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', class_weight=None, colsample_bytree=0.7,\n",
       "               importance_type='split', learning_rate=0.1, max_bin=510,\n",
       "               max_depth=7, min_child_samples=20, min_child_weight=0.001,\n",
       "               min_split_gain=0.0, n_estimators=1000, n_jobs=-1, num_leaves=80,\n",
       "               objective='categorical', random_state=0, reg_alpha=0.0,\n",
       "               reg_lambda=0.0, silent=True, subsample=0.7,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators=1000\n",
    "lgb = LGBMClassifier(n_estimators=n_estimators, random_state=0, objective='categorical', boosting_type = 'dart', max_bin = 510,\n",
    "                    colsample_bytree = 0.7, subsample=0.7, **best, num_leaves = 80, n_jobs=-1)\n",
    "lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds==y_test)/len(y_test) #0.416-->0.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgb_comb2.sav']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(lgb, 'lgb_comb2.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:  3.8min finished\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [1, 4, 10], 'penalty': ['l2', 'none'],\n",
       "                         'solver': ['newton-cg', 'lbfgs']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "params = {'penalty':['l2','none'], 'C':[1,4,10], 'solver':['newton-cg', 'lbfgs']}\n",
    "lr_cv = GridSearchCV(lr, params, scoring='accuracy', verbose=2, n_jobs=-1, refit = True)\n",
    "lr_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'none', 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.428"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lr_cv.predict(X_test)==y_test)/len(y_test) #0.286-->0.428"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiyoung Sim\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   53.1s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10],\n",
       "                         'gamma': [0.001, 0.01, 0.1, 1],\n",
       "                         'kernel': ['linear', 'rbf', 'poly']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "params = {'kernel':['linear', 'rbf', 'poly'],'C': [0.001, 0.01, 0.1, 1, 10], 'gamma':[0.001, 0.01, 0.1, 1]}\n",
    "svm_cv = GridSearchCV(svm, params, scoring='accuracy', verbose=2, n_jobs=-1, refit=True)\n",
    "svm_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001, 'gamma': 0.001, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7., 20., 14.,  7., 17., 21., 10., 10., 21.,  8., 20.,  6., 10.,\n",
       "       20.,  9.,  3., 22., 21.,  6., 19., 18., 16., 11.,  8., 20.,  1.,\n",
       "       19., 13., 21.,  8., 10., 15.,  5.,  4., 22., 22.,  7.,  6., 11.,\n",
       "       20.,  3.,  1.,  4.,  6.,  4., 11., 19.,  6., 22., 22., 19., 10.,\n",
       "        6., 16., 18., 12.,  3.,  8., 21., 22., 11.,  8., 15.,  4., 14.,\n",
       "       16.,  3.,  3.,  4., 16., 11., 17.,  3., 14., 18.,  8., 18.,  3.,\n",
       "       11., 11.,  5.,  9.,  6., 19.,  7.,  9.,  5., 14.,  5.,  7., 21.,\n",
       "       13., 21., 20.,  4.,  3., 16., 18.,  6., 12., 17., 20.,  7., 17.,\n",
       "        5., 20., 14.,  8.,  2.,  9.,  4., 17., 19.,  2., 18., 17.,  4.,\n",
       "        4.,  8., 22., 16., 11.,  9., 21., 19.,  4.,  1., 17.,  2.,  5.,\n",
       "        8., 13.,  3., 19.,  9.,  4.,  3.,  3.,  9.,  7., 10., 14.,  5.,\n",
       "       20., 19.,  4.,  5., 14., 20., 20.,  4., 19., 17., 20.,  3., 16.,\n",
       "        7., 13.,  4., 22.,  5., 16.,  2.,  8., 12.,  7.,  6., 19.,  5.,\n",
       "        7.,  4.,  9.,  5., 10.,  3.,  1.,  4.,  7., 20.,  4., 15., 16.,\n",
       "        2., 14., 20.,  3., 14.,  8., 17.,  5.,  3.,  1.,  4.,  5., 19.,\n",
       "        4., 15.,  2., 22., 12.,  7.,  1., 17.,  4., 22., 19., 21., 19.,\n",
       "       13.,  1.,  8., 15., 11.,  9., 18., 14.,  8.,  9.,  5.,  4., 10.,\n",
       "        7.,  4., 14., 22., 12., 10.,  9.,  2., 14., 19.,  1., 11.,  2.,\n",
       "        7.,  4.,  6.,  9.,  8.,  9.,  8., 12., 10., 20., 10., 12., 12.,\n",
       "       12.,  9., 14., 13.,  9.,  7.,  2., 10.,  7., 19.,  4., 20., 20.,\n",
       "       10., 22.,  1., 17.,  8., 16.,  6., 20.,  1.,  6., 11., 17., 15.,\n",
       "        7.,  9., 21.,  4., 17.,  2.,  2.,  4., 19., 21.,  9.,  1.,  1.,\n",
       "        6., 19., 11., 18., 11.,  3.,  1., 21.,  4., 22.,  7., 18.,  4.,\n",
       "       15.,  2., 10., 20., 21., 11., 15.,  3.,  1.,  2., 17., 22.,  9.,\n",
       "        9.,  6., 20.,  1., 10.,  3., 16.,  1.,  8., 22.,  6.,  3., 22.,\n",
       "        8., 18., 19.,  3., 19.,  7.,  4.,  2.,  6.,  3.,  4., 14.,  7.,\n",
       "       22.,  8.,  7., 11., 14., 12., 13.,  7., 14.,  3.,  1., 10., 10.,\n",
       "       10.,  3.,  9., 17., 15.,  6., 18., 19., 19.,  3.,  1.,  2.,  7.,\n",
       "        7.,  2., 13., 17.,  4., 18., 15., 17., 14.,  4.,  4.,  7., 20.,\n",
       "       15., 19.,  6., 20., 20.,  2., 21.,  9.,  7., 17., 18., 17., 19.,\n",
       "        8., 19., 16.,  2., 14., 14.,  4., 12., 10.,  3., 20., 12., 13.,\n",
       "       22.,  4.,  8.,  1., 22.,  5.,  6., 14.,  1.,  4.,  3.,  1., 20.,\n",
       "       10.,  3.,  3., 14.,  2.,  8., 17., 15., 22., 15., 14., 16., 14.,\n",
       "        8., 15.,  3., 21., 15.,  8., 10., 16.,  5., 16., 10., 11.,  4.,\n",
       "       17., 14., 17., 21.,  2., 16., 17., 12.,  3.,  8.,  9., 10.,  9.,\n",
       "       11., 10., 17., 10.,  4.,  1., 11., 15., 16.,  7.,  4.,  2.,  4.,\n",
       "       17.,  1., 10.,  2.,  6.,  5.,  8., 11., 12.,  3.,  8.,  5.,  5.,\n",
       "       14., 21., 14., 18., 16., 16., 10.,  2.,  2.,  6., 19., 17.,  4.,\n",
       "       11., 13., 12., 11., 20., 20.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.426"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(svm_cv.predict(X_test)==y_test)/len(y_test) #0.358-->0.426"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "params = {'n_estimators':[100, 250, 500, 750, 1000, 5000]}\n",
    "rf_cv = GridSearchCV(rf, params, scoring='f1_weighted', n_jobs=-1)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "n_estimators = rf_cv.best_params_['n_estimators']\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators, random_state=0)\n",
    "params = {'max_depth': [1, 5, 10, 20, 50],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion' :['gini', 'entropy']}\n",
    "rf_cv = GridSearchCV(rf, params, scoring='accuracy', n_jobs=-1, refit=True)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "# rf = RandomForestClassifier(max_depth=50, n_estimators=1000, criterion='gini', max_features='auto')\n",
    "# rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rf_cv.predict(X_test)==y_test)/len(y_test) #0.396-->0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('model1',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=50,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=1000,\n",
       "                                                     n_jobs=-1, oob_score=False,\n",
       "                                                     random_state=None,\n",
       "                                                     verbo...\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('model4',\n",
       "                              SVC(C=0.001, cache_size=200, class_weight=None,\n",
       "                                  coef0=0.0, decision_function_shape='ovr',\n",
       "                                  degree=3, gamma=0.001, kernel='linear',\n",
       "                                  max_iter=-1, probability=True,\n",
       "                                  random_state=None, shrinking=True, tol=0.001,\n",
       "                                  verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=-1, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "models = [('model1',RandomForestClassifier(max_depth=50, n_estimators=1000, criterion='gini', max_features='auto', n_jobs=-1)),\n",
    "            ('model2',LGBMClassifier(n_estimators=n_estimators, random_state=0, objective='multiclass', boosting_type = 'dart', max_bin = 510,\n",
    "                    colsample_pytree = 0.7, subsample=0.7, learning_rate=0.1, max_depth=7, num_leaves = 80, n_jobs=-1)),\n",
    "            ('model3',LogisticRegression(solver='lbfgs', multi_class='multinomial', C=1, penalty='none')),\n",
    "            ('model4',SVC(kernel='linear',C=0.001, gamma=0.001, probability=True))\n",
    "            ]\n",
    "vote1=VotingClassifier(models, voting='soft', weights=None, n_jobs=-1, flatten_transform=True)\n",
    "vote1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.434"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(vote1.predict(X_test)==y_test)/len(y_test) #0.4-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
