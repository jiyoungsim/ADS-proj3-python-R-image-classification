{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(X_train, y_train, cv):\n",
    "    from lightgbm import LGBMClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    import time\n",
    "    \n",
    "    if(cv):\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        params = {'n_estimators':[100, 200, 500, 1000]}\n",
    "        lgb = LGBMClassifier(random_state=0, objective='multiclass', boosting_type = 'dart', max_bin = 510,\n",
    "                            colsample_bytree = 0.7, subsample=0.7)\n",
    "        clf = GridSearchCV(lgb, params, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        n_estimators = clf.best_params_['n_estimators']\n",
    "        \n",
    "        params = {'learning_rate':[0.1, 0.05, 0.01], 'max_depth':[3, 5, 7]}\n",
    "        lgb = LGBMClassifier(n_estimators=n_estimators, random_state=0, objective='multiclass', boosting_type = 'dart', max_bin = 510,\n",
    "                            colsample_bytree = 0.7, subsample=0.7)\n",
    "        clf = GridSearchCV(lgb, params, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        best = clf.best_params_\n",
    "        lgb_params = {'objective':'multiclass', 'boosting_type':'dart', 'max_bin':510,\n",
    "                            'colsample_bytree':0.7, 'subsample':0.7, 'n_estimators':n_estimators,\n",
    "                      'learning_rate':best['learning_rate'], 'max_depth':best['max_depth']}\n",
    "        \n",
    "        lr = LogisticRegression()\n",
    "        params = {'penalty':['l2','none'], 'C':[1,4,10], 'solver':['newton-cg', 'lbfgs']}\n",
    "        lr_cv = GridSearchCV(lr, params, scoring='accuracy', verbose=2, n_jobs=-1, refit = True)\n",
    "        lr_cv.fit(X_train, y_train)\n",
    "        lr_params = lr_cv.best_params_\n",
    "        \n",
    "        svm = SVC()\n",
    "        params = {'kernel':['linear', 'rbf', 'poly'],'C': [0.001, 0.01, 0.1, 1, 10], 'gamma':[0.001, 0.01, 0.1, 1]}\n",
    "        svm_cv = GridSearchCV(svm, params, scoring='accuracy', verbose=2, n_jobs=-1, refit=True)\n",
    "        svm_cv.fit(X_train, y_train)\n",
    "        svm_params = svm_cv.best_params_\n",
    "        svm_params['probability'] = True\n",
    "\n",
    "        rf = RandomForestClassifier(random_state=0)\n",
    "        params = {'n_estimators':[100, 200, 500, 1000]}\n",
    "        rf_cv = GridSearchCV(rf, params, scoring='f1_weighted', n_jobs=-1)\n",
    "        rf_cv.fit(X_train, y_train)\n",
    "        n_estimators = rf_cv.best_params_['n_estimators']\n",
    "\n",
    "        rf = RandomForestClassifier(n_estimators=n_estimators, random_state=0)\n",
    "        params = {'max_depth': [1, 5, 10, 20, 50],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'criterion' :['gini', 'entropy']}\n",
    "        rf_cv = GridSearchCV(rf, params, scoring='accuracy', n_jobs=-1, refit=True)\n",
    "        rf_cv.fit(X_train, y_train)\n",
    "        best = rf_cv.best_params_\n",
    "        rf_params = {'max_depth':best['max_depth'], 'n_estimators':n_estimators, 'criterion':best['criterion'], 'max_features':best['max_features']}  \n",
    "    else:\n",
    "        lgb_params = {'objective':'multiclass', 'boosting_type':'dart', 'max_bin':510,\n",
    "                            'colsample_bytree':0.7, 'subsample':0.7, 'n_estimators':1000,\n",
    "                      'learning_rate':0.01, 'max_depth':7}\n",
    "        lr_params = {'penalty':'none','C':1, 'solver':'lbfgs'}\n",
    "        svm_params = {'kernel':'linear','C':0.001, 'gamma':0.001, 'probability':True}\n",
    "        rf_params = {'max_depth':50, 'n_estimators':1000, 'criterion':'gini', 'max_features':'auto'}  \n",
    "        \n",
    "    models = [('model1',LGBMClassifier(**lgb_params)),\n",
    "        ('model2',LogisticRegression(**lr_params)),\n",
    "        ('model3',SVC(**svm_params)),\n",
    "        ('model4',RandomForestClassifier(**rf_params))\n",
    "        ]\n",
    "    start=time.time()\n",
    "    vote=VotingClassifier(models, voting='soft', weights=None, flatten_transform=True, n_jobs=-1)\n",
    "    vote.fit(X_train, y_train)\n",
    "    end=time.time()\n",
    "    time=end-start\n",
    "    \n",
    "    return time, vote"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
